{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X_train_transformed = pd.read_csv('CSV/pre-processed/full_X_train_transformed')\n",
    "full_y_train = pd.read_csv('CSV/pre-processed/full_y_train')\n",
    "full_y_train = full_y_train.drop(columns=['id'])\n",
    "full_y_train = full_y_train.iloc[:, 0]\n",
    "\n",
    "\n",
    "\n",
    "full_X_test_transformed = pd.read_csv('CSV/pre-processed/full_X_test_transformed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting only the image data from the full_X_train_transformed DataFrame\n",
    "image_data_train = full_X_train_transformed.iloc[:, -40000:]\n",
    "image_data_test = full_X_test_transformed.iloc[:, -40000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data_train.columns = range(40000)\n",
    "image_data_test.columns = range(40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data_train = image_data_train.values.reshape(-1, 200, 200)\n",
    "image_data_test = image_data_test.values.reshape(-1, 200, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(990, 200, 200)\n",
      "(594, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "print(image_data_train.shape)\n",
    "print(image_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (792, 200, 200)\n",
      "Validation set size: (198, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "y_train_encoded = encoder.fit_transform(full_y_train)\n",
    "\n",
    "# Splitting 20% of the training data as a validation set\n",
    "X_train, X_val, y_train_encoded_split, y_val_encoded_split = train_test_split(\n",
    "    image_data_train, y_train_encoded, test_size=0.2, stratify=y_train_encoded, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Validation set size: {X_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        # Calculate the size of the flattened output after the conv and pooling layers\n",
    "        flattened_size = 64 * 50 * 50\n",
    "        \n",
    "        self.fc1 = nn.Linear(flattened_size, 512)\n",
    "        self.fc2 = nn.Linear(512, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 50 * 50)  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntermediateCNN(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super(IntermediateCNN, self).__init__()\n",
    "\n",
    "        # First Convolutional Block\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Second Convolutional Block\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(64 * 50 * 50, 512)\n",
    "        self.fc_dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First Convolutional Block\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "\n",
    "        # Second Convolutional Block\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "\n",
    "        # Flatten the tensor\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc_dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedCNN(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super(EnhancedCNN, self).__init__()\n",
    "\n",
    "        # First Convolutional Block\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Second Convolutional Block\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(64 * 50 * 50, 512)\n",
    "        self.fc_dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc_dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(256, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First Convolutional Block\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "\n",
    "        # Second Convolutional Block\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool2(F.relu(self.bn3(self.conv3(x))))\n",
    "\n",
    "        # Flatten the tensor\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc_dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc_dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexCNN(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super(ComplexCNN, self).__init__()\n",
    "\n",
    "        # First Convolutional Block\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Second Convolutional Block\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(128 * 50 * 50, 512)\n",
    "        self.fc_dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc_dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(256, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First Convolutional Block\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool1(F.relu(self.bn2(self.conv2(x))))\n",
    "\n",
    "        # Second Convolutional Block\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool2(F.relu(self.bn4(self.conv4(x))))\n",
    "\n",
    "        # Flatten the tensor\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc_dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc_dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train_encoded_split, dtype=torch.int64).to(device)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val_encoded_split, dtype=torch.int64).to(device)\n",
    "\n",
    "X_test_array = image_data_test.reshape(-1, 1, 200, 200)\n",
    "X_test_tensor = torch.tensor(X_test_array, dtype=torch.float32).to(device)\n",
    "\n",
    "n_classes = full_y_train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHOOSE MODEL BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ComplexCNN(output_dim=n_classes) #Choose the model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComplexCNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=320000, out_features=512, bias=True)\n",
      "  (fc_dropout1): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc_dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc3): Linear(in_features=256, out_features=99, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# Define the loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0, path='models/CNN/best_model.pth'):\n",
    "        \"\"\"\n",
    "        Early stops the training if validation loss doesn't improve after a given patience.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        torch.save(model.state_dict(), self.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Training Loss: 5.4864472331422744, Validation Loss: 4.566591668128967\n",
      "Epoch [2/1000], Training Loss: 4.667484730181068, Validation Loss: 4.550795555114746\n",
      "Epoch [3/1000], Training Loss: 4.6445719942902075, Validation Loss: 4.553221321105957\n",
      "Epoch [4/1000], Training Loss: 4.587035395882347, Validation Loss: 4.444158959388733\n",
      "Epoch [5/1000], Training Loss: 4.558396059455293, Validation Loss: 4.383119773864746\n",
      "Epoch [6/1000], Training Loss: 4.47414824155846, Validation Loss: 4.334078073501587\n",
      "Epoch [7/1000], Training Loss: 4.426790629372452, Validation Loss: 4.275973963737488\n",
      "Epoch [8/1000], Training Loss: 4.370572353252257, Validation Loss: 4.157574760913849\n",
      "Epoch [9/1000], Training Loss: 4.24381404814094, Validation Loss: 3.990017855167389\n",
      "Epoch [10/1000], Training Loss: 4.156033228142093, Validation Loss: 3.9506891489028932\n",
      "Epoch [11/1000], Training Loss: 4.113315500394262, Validation Loss: 3.9247932195663453\n",
      "Epoch [12/1000], Training Loss: 4.043553411358535, Validation Loss: 3.855787444114685\n",
      "Epoch [13/1000], Training Loss: 3.9636055146804963, Validation Loss: 3.850339925289154\n",
      "Epoch [14/1000], Training Loss: 3.9434652180984764, Validation Loss: 3.820031189918518\n",
      "Epoch [15/1000], Training Loss: 3.7627503290922952, Validation Loss: 3.723948907852173\n",
      "Epoch [16/1000], Training Loss: 3.6631227623332627, Validation Loss: 3.5864084482192995\n",
      "Epoch [17/1000], Training Loss: 3.6676108114647143, Validation Loss: 3.5857149600982665\n",
      "Epoch [18/1000], Training Loss: 3.669800716217118, Validation Loss: 3.485018181800842\n",
      "Epoch [19/1000], Training Loss: 3.4993966856990197, Validation Loss: 3.3608436703681948\n",
      "Epoch [20/1000], Training Loss: 3.4278446496135055, Validation Loss: 3.318547236919403\n",
      "Epoch [21/1000], Training Loss: 3.504729623144323, Validation Loss: 3.323231840133667\n",
      "Epoch [22/1000], Training Loss: 3.2711444719873293, Validation Loss: 3.278703141212463\n",
      "Epoch [23/1000], Training Loss: 3.283874150177445, Validation Loss: 3.1050102531909944\n",
      "Epoch [24/1000], Training Loss: 3.218339911916039, Validation Loss: 3.1520989298820496\n",
      "Epoch [25/1000], Training Loss: 3.1951694943086064, Validation Loss: 3.161889684200287\n",
      "Epoch [26/1000], Training Loss: 3.160698355147333, Validation Loss: 3.1914970517158507\n",
      "Epoch [27/1000], Training Loss: 3.0567733529541226, Validation Loss: 2.9681082367897034\n",
      "Epoch [28/1000], Training Loss: 3.0305535880604175, Validation Loss: 3.0064597606658934\n",
      "Epoch [29/1000], Training Loss: 2.8549973907494786, Validation Loss: 2.9641182124614716\n",
      "Epoch [30/1000], Training Loss: 2.798702514006032, Validation Loss: 3.0367210507392883\n",
      "Epoch [31/1000], Training Loss: 2.8030637448484246, Validation Loss: 2.99535813331604\n",
      "Epoch [32/1000], Training Loss: 2.7991314593589665, Validation Loss: 2.812355637550354\n",
      "Epoch [33/1000], Training Loss: 2.758815304347963, Validation Loss: 2.8057168662548064\n",
      "Epoch [34/1000], Training Loss: 2.583190861976508, Validation Loss: 2.6935461521148683\n",
      "Epoch [35/1000], Training Loss: 2.542386614915096, Validation Loss: 2.7173156142234802\n",
      "Epoch [36/1000], Training Loss: 2.557825752430492, Validation Loss: 2.7197242736816407\n",
      "Epoch [37/1000], Training Loss: 2.5455905293876473, Validation Loss: 2.598226845264435\n",
      "Epoch [38/1000], Training Loss: 2.411777052012357, Validation Loss: 2.6644856512546538\n",
      "Epoch [39/1000], Training Loss: 2.444595611005118, Validation Loss: 2.5442415833473206\n",
      "Epoch [40/1000], Training Loss: 2.376525156726741, Validation Loss: 2.5554245173931123\n",
      "Epoch [41/1000], Training Loss: 2.3193868246876677, Validation Loss: 2.4583911061286927\n",
      "Epoch [42/1000], Training Loss: 2.156165133823048, Validation Loss: 2.472717595100403\n",
      "Epoch [43/1000], Training Loss: 2.2018272948987554, Validation Loss: 2.4073247373104096\n",
      "Epoch [44/1000], Training Loss: 2.058333177733908, Validation Loss: 2.376895177364349\n",
      "Epoch [45/1000], Training Loss: 1.9973031156743415, Validation Loss: 2.278378301858902\n",
      "Epoch [46/1000], Training Loss: 2.0704116837845907, Validation Loss: 2.232038974761963\n",
      "Epoch [47/1000], Training Loss: 2.0025361965250488, Validation Loss: 2.249058249592781\n",
      "Epoch [48/1000], Training Loss: 1.9449205692819873, Validation Loss: 2.266678363084793\n",
      "Epoch [49/1000], Training Loss: 2.1214134539618636, Validation Loss: 2.200568524003029\n",
      "Epoch [50/1000], Training Loss: 2.020144610091893, Validation Loss: 2.1710088193416595\n",
      "Epoch [51/1000], Training Loss: 1.8559201110643568, Validation Loss: 2.1931811720132828\n",
      "Epoch [52/1000], Training Loss: 1.9771077179095962, Validation Loss: 2.135625159740448\n",
      "Epoch [53/1000], Training Loss: 1.8016250232086128, Validation Loss: 2.0835939675569533\n",
      "Epoch [54/1000], Training Loss: 1.7398427455977659, Validation Loss: 2.142009487748146\n",
      "Epoch [55/1000], Training Loss: 1.6563773623460696, Validation Loss: 2.0324603736400606\n",
      "Epoch [56/1000], Training Loss: 1.7889598939118605, Validation Loss: 2.1889984130859377\n",
      "Epoch [57/1000], Training Loss: 1.5913298647060539, Validation Loss: 2.0649387180805205\n",
      "Epoch [58/1000], Training Loss: 1.5698430489503539, Validation Loss: 2.00559401512146\n",
      "Epoch [59/1000], Training Loss: 1.6329797583095955, Validation Loss: 2.016120934486389\n",
      "Epoch [60/1000], Training Loss: 1.5634289090380524, Validation Loss: 1.9924447149038316\n",
      "Epoch [61/1000], Training Loss: 1.570967034239209, Validation Loss: 1.976232796907425\n",
      "Epoch [62/1000], Training Loss: 1.5459256617803916, Validation Loss: 1.9150921553373337\n",
      "Epoch [63/1000], Training Loss: 1.4902470499803924, Validation Loss: 1.9417284995317459\n",
      "Epoch [64/1000], Training Loss: 1.5662445263193938, Validation Loss: 1.9298851191997528\n",
      "Epoch [65/1000], Training Loss: 1.4187889868943866, Validation Loss: 1.9788494348526\n",
      "Epoch [66/1000], Training Loss: 1.3884253890225382, Validation Loss: 1.8424456417560577\n",
      "Epoch [67/1000], Training Loss: 1.3456895770599142, Validation Loss: 1.8735872447490691\n",
      "Epoch [68/1000], Training Loss: 1.194180749483745, Validation Loss: 1.8432378768920898\n",
      "Epoch [69/1000], Training Loss: 1.2515153386394935, Validation Loss: 1.8189771264791488\n",
      "Epoch [70/1000], Training Loss: 1.3148761512429425, Validation Loss: 1.76757250726223\n",
      "Epoch [71/1000], Training Loss: 1.2396255513709602, Validation Loss: 1.7561155080795288\n",
      "Epoch [72/1000], Training Loss: 1.2007585389897075, Validation Loss: 1.7830953910946845\n",
      "Epoch [73/1000], Training Loss: 1.1817486042326146, Validation Loss: 1.766445705294609\n",
      "Epoch [74/1000], Training Loss: 1.1711728709016107, Validation Loss: 1.783995020389557\n",
      "Epoch [75/1000], Training Loss: 1.0547486207761179, Validation Loss: 1.7606482595205306\n",
      "Epoch [76/1000], Training Loss: 1.0623269975614602, Validation Loss: 1.7374943912029266\n",
      "Epoch [77/1000], Training Loss: 1.1076220454215402, Validation Loss: 1.7240283578634261\n",
      "Epoch [78/1000], Training Loss: 1.0670944322088751, Validation Loss: 1.67580456584692\n",
      "Epoch [79/1000], Training Loss: 1.0170245224332455, Validation Loss: 1.7115238294005395\n",
      "Epoch [80/1000], Training Loss: 1.0828568080364904, Validation Loss: 1.6716348871588707\n",
      "Epoch [81/1000], Training Loss: 1.015679116579563, Validation Loss: 1.7254821375012397\n",
      "Epoch [82/1000], Training Loss: 1.0177105548556404, Validation Loss: 1.6939988255500793\n",
      "Epoch [83/1000], Training Loss: 0.8307687904817438, Validation Loss: 1.630796055495739\n",
      "Epoch [84/1000], Training Loss: 1.023390865703006, Validation Loss: 1.6310856550931931\n",
      "Epoch [85/1000], Training Loss: 0.9352679722698409, Validation Loss: 1.6162628367543221\n",
      "Epoch [86/1000], Training Loss: 0.8421060081096272, Validation Loss: 1.6221887797117234\n",
      "Epoch [87/1000], Training Loss: 0.889989049785366, Validation Loss: 1.660688090324402\n",
      "Epoch [88/1000], Training Loss: 0.8458881921780464, Validation Loss: 1.5931783378124238\n",
      "Epoch [89/1000], Training Loss: 0.8454802524147912, Validation Loss: 1.6901449099183083\n",
      "Epoch [90/1000], Training Loss: 0.8481590925113797, Validation Loss: 1.6167097121477128\n",
      "Epoch [91/1000], Training Loss: 0.8335249708739645, Validation Loss: 1.5982173822820187\n",
      "Epoch [92/1000], Training Loss: 0.8315626889787088, Validation Loss: 1.5826605916023255\n",
      "Epoch [93/1000], Training Loss: 0.6781628971914714, Validation Loss: 1.517270040512085\n",
      "Epoch [94/1000], Training Loss: 0.7828273737539697, Validation Loss: 1.578632155060768\n",
      "Epoch [95/1000], Training Loss: 0.8215013633698526, Validation Loss: 1.6106778621673583\n",
      "Epoch [96/1000], Training Loss: 0.7389364702741126, Validation Loss: 1.5886145025491714\n",
      "Epoch [97/1000], Training Loss: 0.7301165734540032, Validation Loss: 1.6063409209251405\n",
      "Epoch [98/1000], Training Loss: 0.7600956861278974, Validation Loss: 1.5502393931150436\n",
      "Epoch [99/1000], Training Loss: 0.7465262541246384, Validation Loss: 1.5711285457015038\n",
      "Epoch [100/1000], Training Loss: 0.6425616390899651, Validation Loss: 1.5469543486833572\n",
      "Epoch [101/1000], Training Loss: 0.6609499920865125, Validation Loss: 1.5640730157494545\n",
      "Epoch [102/1000], Training Loss: 0.6288661910079871, Validation Loss: 1.5562753677368164\n",
      "Epoch [103/1000], Training Loss: 0.6364130964511512, Validation Loss: 1.5639352679252625\n",
      "Epoch [104/1000], Training Loss: 0.6007464371169757, Validation Loss: 1.5792627841234208\n",
      "Epoch [105/1000], Training Loss: 0.6312646364764959, Validation Loss: 1.585770682990551\n",
      "Epoch [106/1000], Training Loss: 0.5958840541184098, Validation Loss: 1.5747939825057984\n",
      "Epoch [107/1000], Training Loss: 0.6076479672673017, Validation Loss: 1.5261095672845841\n",
      "Epoch [108/1000], Training Loss: 0.5319482140395959, Validation Loss: 1.5236576735973357\n",
      "Epoch [109/1000], Training Loss: 0.48701192143860017, Validation Loss: 1.492854756116867\n",
      "Epoch [110/1000], Training Loss: 0.6325910544973055, Validation Loss: 1.514608310163021\n",
      "Epoch [111/1000], Training Loss: 0.6161892269786984, Validation Loss: 1.510067741572857\n",
      "Epoch [112/1000], Training Loss: 0.5309326188154331, Validation Loss: 1.5334574475884437\n",
      "Epoch [113/1000], Training Loss: 0.5041445660724687, Validation Loss: 1.5224660158157348\n",
      "Epoch [114/1000], Training Loss: 0.5337665434453429, Validation Loss: 1.462580320239067\n",
      "Epoch [115/1000], Training Loss: 0.5124269252421918, Validation Loss: 1.4747171193361281\n",
      "Epoch [116/1000], Training Loss: 0.47116328256599826, Validation Loss: 1.4615831524133682\n",
      "Epoch [117/1000], Training Loss: 0.5029819162986442, Validation Loss: 1.4683673113584519\n",
      "Epoch [118/1000], Training Loss: 0.49100542998365365, Validation Loss: 1.4822743028402328\n",
      "Epoch [119/1000], Training Loss: 0.5416371169849299, Validation Loss: 1.468874880671501\n",
      "Epoch [120/1000], Training Loss: 0.4869256776359492, Validation Loss: 1.4700989335775376\n",
      "Epoch [121/1000], Training Loss: 0.39494437572424007, Validation Loss: 1.468336171656847\n",
      "Epoch [122/1000], Training Loss: 0.40072546815593735, Validation Loss: 1.501178652048111\n",
      "Epoch [123/1000], Training Loss: 0.3946053012368977, Validation Loss: 1.4760285966098308\n",
      "Epoch [124/1000], Training Loss: 0.44939524345174886, Validation Loss: 1.4591735631227494\n",
      "Epoch [125/1000], Training Loss: 0.4715213813993026, Validation Loss: 1.4666431277990342\n",
      "Epoch [126/1000], Training Loss: 0.45689396532337684, Validation Loss: 1.5048499345779418\n",
      "Epoch [127/1000], Training Loss: 0.43986586871794253, Validation Loss: 1.488081055879593\n",
      "Epoch [128/1000], Training Loss: 0.3672645235865378, Validation Loss: 1.4732199974358082\n",
      "Epoch [129/1000], Training Loss: 0.37749941101363294, Validation Loss: 1.506678256392479\n",
      "Epoch [130/1000], Training Loss: 0.40146696165196993, Validation Loss: 1.4961272291839123\n",
      "Epoch [131/1000], Training Loss: 0.33641844196112786, Validation Loss: 1.5033646065741777\n",
      "Epoch [132/1000], Training Loss: 0.3915166440525634, Validation Loss: 1.52425691857934\n",
      "Epoch [133/1000], Training Loss: 0.3773504610977728, Validation Loss: 1.4233281545341014\n",
      "Epoch [134/1000], Training Loss: 0.40268450636167374, Validation Loss: 1.4225042566657067\n",
      "Epoch [135/1000], Training Loss: 0.3851974117828247, Validation Loss: 1.4691584318876267\n",
      "Epoch [136/1000], Training Loss: 0.35970587863097664, Validation Loss: 1.6447530403733253\n",
      "Epoch [137/1000], Training Loss: 0.33154260438224276, Validation Loss: 1.5329650677740574\n",
      "Epoch [138/1000], Training Loss: 0.4012188502806245, Validation Loss: 1.5111590430140496\n",
      "Epoch [139/1000], Training Loss: 0.4281417250920162, Validation Loss: 1.531394761800766\n",
      "Epoch [140/1000], Training Loss: 0.3849877898403175, Validation Loss: 1.43272205889225\n",
      "Epoch [141/1000], Training Loss: 0.329268707106411, Validation Loss: 1.5207994133234024\n",
      "Epoch [142/1000], Training Loss: 0.37976364531046286, Validation Loss: 1.5222966387867927\n",
      "Epoch [143/1000], Training Loss: 0.3839293682613795, Validation Loss: 1.481405859440565\n",
      "Epoch [144/1000], Training Loss: 0.31947382668412766, Validation Loss: 1.484487222135067\n",
      "Epoch [145/1000], Training Loss: 0.39730901703340793, Validation Loss: 1.4000363893806935\n",
      "Epoch [146/1000], Training Loss: 0.3430812229899774, Validation Loss: 1.4803181894123554\n",
      "Epoch [147/1000], Training Loss: 0.30245309585072594, Validation Loss: 1.4663750313222408\n",
      "Epoch [148/1000], Training Loss: 0.3033846844901387, Validation Loss: 1.5624650210142135\n",
      "Epoch [149/1000], Training Loss: 0.2526046344707602, Validation Loss: 1.5094385653734208\n",
      "Epoch [150/1000], Training Loss: 0.2833093614334656, Validation Loss: 1.5172026228159665\n",
      "Epoch [151/1000], Training Loss: 0.2928015648031953, Validation Loss: 1.3921958848834037\n",
      "Epoch [152/1000], Training Loss: 0.2688120468975294, Validation Loss: 1.377686394751072\n",
      "Epoch [153/1000], Training Loss: 0.2435224532771079, Validation Loss: 1.3879841215908528\n",
      "Epoch [154/1000], Training Loss: 0.2815067190150707, Validation Loss: 1.498298267275095\n",
      "Epoch [155/1000], Training Loss: 0.38358320793838974, Validation Loss: 1.4906824104487897\n",
      "Epoch [156/1000], Training Loss: 0.3449551838635634, Validation Loss: 1.4434266105294227\n",
      "Epoch [157/1000], Training Loss: 0.2415625829698084, Validation Loss: 1.420748370140791\n",
      "Epoch [158/1000], Training Loss: 0.25416102013997544, Validation Loss: 1.442793097347021\n",
      "Epoch [159/1000], Training Loss: 0.23566497930483138, Validation Loss: 1.4228892400860786\n",
      "Epoch [160/1000], Training Loss: 0.25639235874875493, Validation Loss: 1.3981338813900948\n",
      "Epoch [161/1000], Training Loss: 0.24499760374763152, Validation Loss: 1.3825949348509312\n",
      "Epoch [162/1000], Training Loss: 0.27889118644016164, Validation Loss: 1.4409236207604408\n",
      "Epoch [163/1000], Training Loss: 0.2877805791818772, Validation Loss: 1.463842386752367\n",
      "Epoch [164/1000], Training Loss: 0.24925676991573895, Validation Loss: 1.4314481735229492\n",
      "Epoch [165/1000], Training Loss: 0.2716990759779377, Validation Loss: 1.4075960002839565\n",
      "Epoch [166/1000], Training Loss: 0.26188355777647837, Validation Loss: 1.3919036149978639\n",
      "Epoch [167/1000], Training Loss: 0.2530459402961894, Validation Loss: 1.4313645571470262\n",
      "Epoch [168/1000], Training Loss: 0.2415919080375155, Validation Loss: 1.3778432354331016\n",
      "Epoch [169/1000], Training Loss: 0.25033027567192817, Validation Loss: 1.413730238005519\n",
      "Epoch [170/1000], Training Loss: 0.25228587708367894, Validation Loss: 1.4329830069094895\n",
      "Epoch [171/1000], Training Loss: 0.21155930280729815, Validation Loss: 1.5061561804264785\n",
      "Epoch [172/1000], Training Loss: 0.29924186992539403, Validation Loss: 1.4199344269931315\n",
      "Early stopping triggered.\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "epochs = 1000\n",
    "batch_size = 10\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping = EarlyStopping(patience=20, path='models/CNN/best_model.pth')\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Ensure the model is in training mode\n",
    "    train_loss = 0.0\n",
    "    for i in range(0, len(X_train_tensor), batch_size):\n",
    "        # Determine end index for the current batch\n",
    "        end_idx = min(i + batch_size, len(X_train_tensor))\n",
    "        \n",
    "        # Get the mini-batch data\n",
    "        inputs = X_train_tensor[i:end_idx]\n",
    "        labels = y_train_tensor[i:end_idx]\n",
    "\n",
    "        # Ensure the input data has an additional channel dimension (assuming grayscale images)\n",
    "        inputs = inputs.unsqueeze(1)  # Add a channel dimension\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Calculate average training loss for the epoch\n",
    "    train_loss /= (len(X_train_tensor) / batch_size)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.unsqueeze(1)  # Add a channel dimension\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    # Calculate average validation loss for the epoch\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Training Loss: {train_loss}, Validation Loss: {val_loss}\")\n",
    "\n",
    "    # Early Stopping check\n",
    "    early_stopping(val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComplexCNN(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=320000, out_features=512, bias=True)\n",
       "  (fc_dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc_dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (fc3): Linear(in_features=256, out_features=99, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ComplexCNN(output_dim=n_classes)\n",
    "model.load_state_dict(torch.load('models/CNN/best_model.pth'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the validation set: 65.66%\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "# Prevent gradient calculations\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(X_val_tensor), batch_size):\n",
    "        # Determine end index for the current batch\n",
    "        end_idx = min(i + batch_size, len(X_val_tensor))\n",
    "        \n",
    "        # Get the mini-batch data\n",
    "        inputs = X_val_tensor[i:end_idx]\n",
    "        labels = y_val_tensor[i:end_idx]\n",
    "        \n",
    "        # Ensure the input data has an additional channel dimension (assuming grayscale images)\n",
    "        inputs = inputs.unsqueeze(1)  # Add a channel dimension\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total_predictions += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct_predictions / total_predictions\n",
    "print(f'Accuracy on the validation set: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Placeholder for the probabilities\n",
    "test_probabilities = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(X_test_tensor), batch_size):\n",
    "        # Get mini-batch\n",
    "        inputs = X_test_tensor[i:i+batch_size]\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Apply softmax to obtain probabilities\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        \n",
    "        test_probabilities.extend(probabilities.cpu().numpy())\n",
    "\n",
    "# Read the sample_submission.csv\n",
    "proba_df = pd.read_csv(\"CSV/sample_submission.csv\")\n",
    "\n",
    "# Replace the data in the columns (excluding the \"id\" column) with the computed probabilities\n",
    "# Ensure that the columns in proba_df (excluding 'id') match the order and number of your model's output classes\n",
    "proba_df.iloc[:, 1:] = test_probabilities\n",
    "\n",
    "# Save to CSV file for submission\n",
    "proba_df.to_csv('CNN_early_stopping_output.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
